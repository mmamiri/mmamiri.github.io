<!-- saved from url=(0039)https://www.mit.edu/~hdanesh/index.html -->
<!-- <html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"> -->


<!-- <html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252"> 
   <script src="./Amiri_files/jquery-1.11.3.min.js"></script>
   <script>
      $(function() {
         $("#includeHtml").load("https://mmamiri.github.io/mmamiri.html");
      });
   </script>
</head>
<body>
   <div id="includeHtml">
<link rel="stylesheet" href="./Amiri_files/jemdoc.css" type="text/css"> -->



<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
    <link rel="stylesheet" href="https://mmamiri.github.io/jemdoc.css" type="text/css">
    
    <title>Mohammad Mohammadi Amiri</title>
    <table summary="Table for page layout." id="tlayout">
    <tbody><tr valign="top">
    <td id="layout-menu">
    <div class="menu-category">Outline</div>
    <div class="menu-item"><a href="https://mmamiri.github.io#research">Research</a></div>
    <div class="menu-item"><a href="https://mmamiri.github.io#publications">Publications</a></div>       
    <div class="menu-item"><a href="https://mmamiri.github.io#members">Members</a></div>
    <div class="menu-item"><a href="https://mmamiri.github.io#awards">Awards</a></div>
    <div class="menu-item"><a href="https://mmamiri.github.io#talk">Talks</a></div>
    <div class="menu-item"><a href="https://mmamiri.github.io#services">Services</a></div>
    <div class="menu-item"><a href="https://mmamiri.github.io#openings">Openings </a></div> 






       
    <style>
    .stt {
  position: fixed;
  right: 1rem;
  bottom: 1rem;
  width: 3rem;
  height: 3rem;
  border-radius: 50%;
  background: rgb(128, 128, 255) url("data:image/svg+xml;utf8,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 384 512'%3E%3Cpath fill='currentColor' d='M352 352c-8.188 0-16.38-3.125-22.62-9.375L192 205.3l-137.4 137.4c-12.5 12.5-32.75 12.5-45.25 0s-12.5-32.75 0-45.25l160-160c12.5-12.5 32.75-12.5 45.25 0l160 160c12.5 12.5 12.5 32.75 0 45.25C368.4 348.9 360.2 352 352 352z'%3E%3C/path%3E%3C/svg%3E") center no-repeat;
  box-shadow: 0 0.25rem 0.5rem 0 gray;
  opacity: 0.7;
}
.stt:hover {
  opacity: 0.8;
}
.stt:focus {
  opacity: 0.9;
}
.stt:active {
  opacity: 1;
}
    </style>

       <a href='#' class="stt" title="scroll to top"></a>







       
    </td><td id="layout-content">
    <div id="toptitle">
    <h1>Mohammad Mohammadi Amiri</h1>
    </div>
    <table class="imgtable"><tbody><tr><td>
    <img style="border:1px solid #7393B3" src="https://github.com/mmamiri/mmamiri.github.io/blob/main/Mohammad_new2.jpg?raw=true" alt="" width="200px">&nbsp;</td>
    


    <td><p>Assistant Professor<br> 
       <a href="https://science.rpi.edu/computer-science" target="_blank">Department of Computer Science</a><br> 
       <a href="https://www.rpi.edu/" target="_blank">Rensselaer Polytechnic Institute (RPI)</a></p><br> 
    
    <h3>Contact</h3>
    <p>MRC 331A<br>
    Troy, NY 12180, USA<br>
    [<a href="mailto:mamiri@rpi.edu">Email</a>]<br>
    [<a href="https://scholar.google.com/citations?hl=en&user=jpJy6SEAAAAJ&view_op=list_works" target="_blank">Google Scholar</a>]
     | [<a href="https://www.linkedin.com/in/mohammad-mohammadi-amiri-6a910754/" target="_blank">LinkedIn</a>]
     | [<a href="https://www.researchgate.net/profile/Mohammad-Amiri-32" target="_blank">ResearchGate</a>]
     | [<a href="https://twitter.com/m_mamiri" target="_blank">X (Twitter)</a>]<br></p>
    </td></tr></tbody></table>
    
    <p><br>   
       Dr. Amiri was appointed an Assistant Professor in the Department of Computer Science at RPI in Fall 2023. 
       His research is mainly dedicated to advancing artificial intelligence through the strategic use of data. 
       In today's rapidly evolving technological landscape, the ability to harness and optimize data is key to unlocking the full potential of intelligent systems.
       Dr. Amiri's research focuses on leveraging data to enhance artificial intelligence's capabilities, aiming to create systems that benefit everyone
       His primary research interests include large language models, data valuation, federated learning, and deep learning.</p>
    
    <p>Dr. Amiri received the Ph.D. degree in Electrical and Electronic Engineering form Imperial College London in 2019. 
       He further received the M.Sc. degree in Electrical and Computer Engineering from the University of Tehran in 2014, and the B.Sc. degree in Electrical Engineering from the Iran University of Science and Technology in 2011, both with the highest rank. 
       He is the recipient of the Best Ph.D. Thesis award from both the Department of Electrical and Electronic Engineering at Imperial College London during the academic year 2018-2019, as well as the IEEE Information Theory Chapter of UK and Ireland in the year 2019. 
       Also, his paper titled &#34;Federated learning over wireless fading channels&#34; received the IEEE Communications Society Young Author Best Paper Award in the year 2022.</p>

       <font face = "Futura" size = 4px color="magenta">For motivated Ph.D. students with strong mathematical and analytical skills: Please send your CV to the above email address if you are interested in Machine Learning and comfortable with programming. 
       </font>
    </p>





    <!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Research %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->   
       
    <a name="research"></a><h2><a name="research"> Research</h2>     
    
    <p>
    <font color="black"> <!--Dr. Amiri's research revolves around the theme of collective intelligence. 
       As the world becomes increasingly interconnected, the wealth of information generated at the periphery of our networks holds the key to a new era of innovation and insight. 
       By tapping into this decentralized data wealth, we not only empower individuals and devices with real-time decision-making capabilities but also foster a collaborative environment where a multitude of perspectives converge to form a unified intelligence. 
       This collective intelligence transcends traditional boundaries, enabling us to tackle complex challenges with unprecedented efficiency and creativity. 
       Embracing the untapped potential of data at the edge is not just a technological advancement; 
       it's a strategic imperative that drives us towards a future where our connected world thrives on the synergy of decentralized insights, propelling us to reach heights we never thought possible. 
       Dr. Amiri's research focuses on using this decentralized data to enhance the system intelligence beneficial for everyone while protecting the sensitive information.
       His research interests include machine learning, data science, information theory, privacy, and optimization. -->
       
    </p>
    <p>
       <!--This is a list of Dr. Amiri's recent research activities:-->
    </font>
    </p>
    
       
    <ul>
       <br>
       <li style="color:black;font-size:16px;"><b>Large language models (LLMs)</b></li>
       <br>
       <p>
          <font color="black">
             <!--In the era of artificial intelligence (AI) and natural language processing, LLMs have emerged as transformative tools, revolutionizing the way we interact with and extract insights from vast troves of textual data. 
          These LLMs, characterized by their enormous size and remarkable capabilities, have found applications across a spectrum of domains, from chatbots and virtual assistants to content generation, translation, information retrieval, and image recognition. 
          Many of these applications rely on adapting one large-scale, pre-trained LLM to multiple downstream applications. 
          Such adaptation is usually done via fine-tuning, which updates the parameters of the pre-trained model. 
          Fine-tuning such massive models is highly resource intensive and require a considerably large amount of on-device memory and compute which can be significantly expensive in terms of time, energy, computing resources, and carbon footprint. 
          Thus, the effective deployment of LLMs yet remains contingent on an imperative challenge: the resource-efficient fine-tuning of these colossal linguistic powerhouses.-->  

          <!--In the era of artificial intelligence (AI) and natural language processing, large language models (LLMs) have become transformative tools, reshaping how we interact with and extract insights from vast amounts of textual data. 
             These models, with their immense scale and capabilities, are central to a wide range of applications, from chatbots and virtual assistants to content generation, translation, and information retrieval. 
             However, the effective deployment of LLMs presents significant challenges, particularly in terms of <b>efficiency</b>, <b>memory usage</b>, <b>reasoning</b>, and <b>data management</b>. 
             Our research group focuses on optimizing the resource-intensive process of fine-tuning LLMs to enhance efficiency in terms of time, energy, and computational resources. 
             We are also addressing the challenge of memory efficiency during LLM inference, ensuring these models can be deployed effectively even in resource-constrained environments. 
             Additionally, we work on improving the reasoning capabilities of LLMs to ensure they generate complex, contextually accurate responses. 
             We explore data valuation methods to prioritize high-quality data in LLM training and investigate how LLMs can be utilized to evaluate and enhance the quality of data.-->

             In the era of artificial intelligence (AI) and natural language processing, large language models (LLMs) have become transformative tools, reshaping how we interact with and extract insights from vast amounts of textual data.
             These models, with their immense scale and capabilities, are central to a wide range of applications, from chatbots and virtual assistants to content generation, translation, and information retrieval.
             However, the effective deployment of LLMs presents significant challenges, particularly in terms of <b>efficiency</b>, <b>memory usage</b>, <b>alignment</b>, <b>data management</b>, and <b>reasoning</b>. 
             Our research group focuses on optimizing the resource-intensive process of fine-tuning LLMs to enhance efficiency in terms of time, energy, and computational resources.
             We are also addressing the challenge of memory efficiency during LLM inference, ensuring these models can be deployed effectively even in resource-constrained environments.
             Moreover, we are dedicated to the critical task of LLM alignment, both through theoretical analysis and empirical studies, to ensure that these models behave in ways that are consistent with intended goals and ethical standards.
             Our research also includes data valuation methods to prioritize high-quality data in LLM training and investigates how LLMs can be utilized to evaluate and enhance the quality of data, creating a feedback loop that benefits both the models and the data they rely on.
             Additionally, we work on improving the reasoning capabilities of LLMs to ensure they generate complex, contextually accurate responses.
          </font>
       </p>
       
       <br>
       <li style="color:black;font-size:16px;"><b>Data valuation</b></li>
       <br>
       <p>
          <font color="black">
          Data is the main fuel of the modern world enabling AI and driving technological growth. 
          The demand for data has grown substantially, and data products have become valuable assets to purchase and sale since it is extremely valuable for sectors to acquire high quality data to discover knowledge. 
          As a valuable resource, it is important to establish a principled method to quantify the worth of the data and its value for the data seekers. 
          This is addressed via data valuation which is the essential component for realization of a fair data trading platform for owners and seekers. 
          </font>
       </p>

       <br>
       <li style="color:black;font-size:16px;"><b>Federated learning/Privacy-preserving machine learning</b></li>
       <br>
       <p>
          <font color="black">
          Today a tremendous amount of data is being generated at different network layers that can be utilized to improve the intelligence of many applications. 
          Privacy-preserving machine learning techniques, such as federated learning, have emerged to exploit the decentralized data while the data stays local to the owner’s device. 
          Specifically, federated learning aims to fit a global model to the decentralized data available locally at the edge devices. 
          The devices receive the global model from the server, update it using their local data, and share the local updates with the server. 
          The server aggregates the local updates, where a common aggregation rule is averaging the local updates, and updates the global model. 
          Besides its applicability, this algorithm imposes various challenges inclduing participaton incentivization, privacy concerns, heterogenous data distribution, model heterogeneity, communication overhead, etc. 
             </font>
       </p>

       <br>
       <li style="color:black;font-size:16px;"><b>Deep learning</b></li>
       <br>
       <p>
          <font color="black">
          The theory of deep learning involves a comprehensive study of the fundamental principles and mathematical foundations that underlie neural networks. 
          This includes understanding the intricacies of network architectures, optimization algorithms, regularization techniques, generalization properties, and how these components contribute to the learning process within deep learning models. 
          The goal is to elucidate the theoretical aspects to improve model interpretability, robustness, and overall performance, advancing the field and its applications.
          </font>
       </p>
    </ul>

     


    <!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Publications %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->   
    
    <a name="publications"></a></p><h2><a name="publications"> Publications</h2>
       
    <ul>
          <br>
          <li style="color:black;font-size:16px;"><b>Book chapters</b></li>
          <br>
    
          <ul>
            <font color="black">
             <li>M. Mohammadi Amiri and D. Gunduz, <b>Machine learning and wireless communications</b>, (edited by H. Vincent Poor, Yonina Eldar, Andrea Goldsmith, and Deniz Gunduz), Cambridge University Press, Cambridge, UK, 2021.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <b>Edge caching for mobile networks</b>, (edited by H. Vincent Poor and Wei Chen), IET Press, London, UK, 2021.</li>
            </font>
            </ul>


          <br>
          <li style="color:black;font-size:16px;"><b>Conference proceedings</b></li>
          <br>
       
          <ul>
             <li><font color="black">A. Falahati and M. Mohammadi Amiri, </font><a href="https://arxiv.org/pdf/2408.12659" target="_blank">Disentangled structural and featural representation for task-agnostic graph valuation</a>, under review.</li>             
             <li>P. Vapakomma, M. Mohammadi Amiri, C. L. Canonne, R. Raskar, and A. Pentland, <a href="https://arxiv.org/pdf/2207.03652.pdf" target="_blank">Private independence testing across two parties</a>, under review.</li>
             <li><font color="black">C. Lu, M. Mohammadi Amiri, and R. Raskar, </font><a href="https://openreview.net/pdf?id=YdI2TULi8E" target="_blank">Private data measurements for decentralized data markets</a>, <i> International Conference on Learning Representations (ICLR) Workshop on Data-Centeric Machine Learning Research (DMLR)</i>, Vienna, Austria, May 2024.</li>
             <li>Z. Wu, M. Mohammadi Amiri, R. Raskar, and B. K. H. Low, <a href="https://openreview.net/pdf?id=FlY7WQ2hWS" target="_blank">Incentive-aware federated learning with training-time model rewards</a>, <i>International Conference on Learning Representations (ICLR)</i>, Vienna, Austria, May 2024.</li>
             <li>A. Chopra, S. K. Sahu, A. Singh, A. Java, P. Vepakomma, M. Mohammadi Amiri, and R. Raskar, <a href="https://web.media.mit.edu/~ayushc/AdaSplit_v2.pdf" target="_blank">Adaptive split learning</a>, <i>Conference on Machine Learning and Systems (MLSys)</i>, Miami Beach, FL, USA, Jun. 2023.</li>
             <li>K. Yang*, M. Mohammadi Amiri*, and S. Kulkarni, <a href="https://ieeexplore.ieee.org/document/10089666" target="_blank">Greedy centroid initialization for federated K-means</a>, <i>Conference on Information Sciences and Systems</i>, Baltimore, MD, USA, Mar. 2023. <br>
              * Equal contribution.</li>
             <li>M. Mohammadi Amiri, F. Berdoz, and R. Raskar, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26106" target="_blank">Fundamentals of task-agnostic data valuation</a>, <i>AAAI Conference on Artificial Intelligence</i>, Washington DC, USA, Feb. 2023.</li>
             <li>M. Mohammadi Amiri, S. R. Kulkarni, and H. V. Poor, <a href="https://arxiv.org/pdf/2107.03510.pdf" target="_blank">Federated learning with downlink device selection</a>, <i>IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)</i>, Lucca, Italy, Sep. 2021.</li>
             <li>M. Mohammadi Amiri, D. Gunduz, S. R. Kulkarni, and H. V. Poor, <a href="https://arxiv.org/pdf/2006.10672.pdf" target="_blank">Federated learning with quantized global model updates</a>, Jun. 2020.</li>
             <li>M. Mohammadi Amiri, D. Gunduz, S. R. Kulkarni, and H. V. Poor, <a href="https://ieeexplore.ieee.org/document/9173960" target="_blank">Update aware device scheduling for federated learning at the wireless edge</a>, <i>IEEE International Symposium on Information Theory (ISIT)</i>, Los Angeles, CA, USA, Jun. 2020.</li>
             <li>M. Mohammadi Amiri, T. M. Duman, and D. Gunduz, <a href="https://arxiv.org/pdf/1907.03909.pdf" target="_blank">Collaborative machine learning at the wireless edge with blind transmitters</a>, <i>IEEE Global Conference on Signal and Information Processing (GlobalSIP)</i>, Ottawa, Canada, Nov. 2019. </li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/MADG_ISIT19.pdf" target="_blank">Machine learning at the wireless edge: distributed stochastic gradient descent over-the-air</a>, <i>IEEE International Symposium on Information Theory (ISIT)</i>, Paris, France, Jul. 2019.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/MAG_SPAWC_19.pdf" target="_blank">Over-the-air machine learning at the wireless edge</a>, <i>IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)</i>, Cannes, France, Jul. 2019.</li>
             <li>J. Zhao, M. Mohammadi Amiri, and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/ZMAG_SPAWC_19.pdf" target="_blank">A low-complexity cache-aided multi-antenna content delivery scheme</a>, <i>IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)</i>, Cannes, France, Jul. 2019.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/AG_ICASSP_19.pdf" target="_blank">Computation scheduling for distributed machine learning with straggling workers</a>, <i>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i>, Brighton, UK, 2019.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/MAG_ISIT_18.pdf" target="_blank">On the capacity region of a cache-aided Gaussian broadcast channel with multi-layer messages</a>, <i>IEEE International Symposium on Information Theory (ISIT)</i>, Colorado, USA, Jun. 2018.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://ieeexplore.ieee.org/document/8007037" target="_blank">Decentralized caching and coded delivery over Gaussian broadcast channels</a>, <i>IEEE International Symposium on Information Theory (ISIT)</i>, Aachen, Germany, Jun. 2017.</li>
             <li>Q. Yang, M. Mohammadi Amiri, and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/ICC17a.pdf" target="_blank">Audience retention rate aware coded video caching</a>, <i>IEEE International Conference on Communications (ICC)</i>, Paris, France, May 2017.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/ICC17c.pdf" target="_blank">Cache-aided data delivery over erasure broadcast channels</a>, <i>IEEE International Conference on Communications (ICC)</i>, Paris, France, May 2017.</li>
             <li>M. Mohammadi Amiri, Q. Yang, and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/Asilomar16.pdf" target="_blank">Decentralized coded caching with distinct cache capacities</a>, <i>Asilomar Conference on Signals, Systems and Computers</i>, Pacific Grove, CA, Nov. 2016.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/ISITA16.pdf" target="_blank">Improved delivery rate-cache capacity trade-off for centralized coded caching</a>, <i>IEEE International Symposium on Information Theory and Its Applications (ISITA)</i>, Monterey, CA, Oct.-Nov. 2016.</li>
             <li>M. Mohammadi Amiri, Q. Yang, and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/ITW16a.pdf" target="_blank">Coded caching for a large number of users</a>, <i>IEEE Information Theory Workshop (ITW)</i>, Cambridge, UK, pp. 171-175, Sep. 2016.</li>
             <li>M. Mohammadi Amiri and A. Olfat, <a href="https://ieeexplore.ieee.org/document/7000873" target="_blank">Low complexity adaptive transmission scheme for cooperative networks with decode-and-forward relay</a>, <i>International Symposium on Telecommunications (IST)</i>, Tehran, Iran, pp. 1128-1132, Sep. 2014.</li>
          </ul>
    
          <br>
          <li style="color:black;font-size:16px;"><b>Journal papers</b></li>
          <br>
          <ul>
             <li><font color="black">D. H. Yang, M. M. Amiri, T. Pedapati, S. Chaudhury, and P. Chen, </font><a href="https://arxiv.org/pdf/2502.00311" target="_blank">Sparse gradient compression for fine-tuning large language models</a>, <i>under review</i>.</li>
             <li><font color="black">K. Yang*, M. Mohammadi Amiri*, and S. Kulkarni, </font><a href="https://link.springer.com/article/10.1007/s10115-024-02066-x#:~:text=a.,corresponding%20sizes%20to%20the%20server." target="_blank">Greedy centroid initialization for federated K-means</a>, <i>Knowledge and Information Systems</i>, vol. 66, pp. 3393-3425, Feb. 2024.</li>
             *Equal contribution
             <li><font color="black">Y.-S. Jeon, M. Mohammadi Amiri, and N. Lee, </font><a href="https://ieeexplore.ieee.org/document/9856665" target="_blank">Communication-efficient federated learning over MIMO multiple access channels</a>, <i>IEEE Transactions on Communications</i>, vol. 70, no. 10, pp. 6547-6562, Oct. 2022.</li>
             <li>H. Hellstrom, J. M. da Silva, M. Mohammadi Amiri, M. Chen, V. Fodor, H. V. Poor, and C. Fischione, <a href="https://ieeexplore.ieee.org/document/9794417" target="_blank">Wireless for machine learning: a survey</a>, <i>Foundations and Trends in Signal Processing</i>, vol. 15, no. 4, pp. 290-399, Jun. 2022.</li>
             <li>M. Mohammadi Amiri, D. Gunduz, S. R. Kulkarni, and H. V. Poor, <a href="https://arxiv.org/pdf/2008.11141.pdf" target="_blank">Convergence of federated learning over a noisy downlink</a>, <i>IEEE Transactions on Wireless Communications</i>, vol. 21, no. 3, pp. 1422-1437, Mar. 2022.</li>
             <li>M. Mohammadi Amiri, T. M. Duman, D. Gunduz, S. R. Kulkarni, and H. V. Poor, <a href="https://arxiv.org/pdf/2010.10030.pdf" target="_blank">Blind federated edge learning</a>, <i></i>IEEE Transactions on Wireless Communications, vol. 20, no. 8, pp. 5129-5143, Aug. 2021.</li>
             <li>M. Mohammadi Amiri, D. Gunduz, S. R. Kulkarni, and H. V. Poor, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/AGKP_20.pdf" target="_blank">Convergence of update aware device scheduling for federated learning at the wireless edge</a>, <i>IEEE Transactions on Wireless Communications</i>, vol. 20, no. 6, pp. 3643-3658, Jun. 2021.</li>
             <li>Y.-S. Jeon, M. Mohammadi Amiri, J. Li, and H. V. Poor, <a href="https://arxiv.org/pdf/2003.08059.pdf" target="_blank">A compressive sensing approach for federated learning over massive MIMO communication systems</a>, <i>IEEE Transactions on Wireless Communications</i>, vol. 20, no. 3, pp. 1990-2004, Mar. 2021.</li>
             <li>D. Gunduz, D. Burth Kurka, M. Jankowski, M. Mohammadi Amiri, E. Ozfatura, and S. Sreekumar, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/Edge_Magazine-13.pdf" target="_blank">Communicate to learn at the edge</a>, <i>IEEE Communication Magazine</i>, vol. 58, no. 12, pp. 14-19, Dec. 2020.  </li>
             <li>J. Zhao, M. Mohammadi Amiri, and D. Gunduz, <a href="https://arxiv.org/pdf/2001.01255.pdf" target="_blank">Multi-antenna coded content delivery with caching: a low-complexity solution</a>, <i>IEEE Transactions on Wireless Communications</i>, vol. 19, no. 11, pp. 7484-7497, Nov. 2020.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://arxiv.org/pdf/1907.09769.pdf" target="_blank">Federated learning over wireless fading channels</a>, <i>IEEE Transactions on Wireless Communications</i>, vol. 19, no. 5, pp. 3546-3557, May 2020 (<b>IEEE Communications Society Young Author Best Paper Award</b>). </li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://arxiv.org/pdf/1901.00844.pdf" target="_blank">Machine learning at the wireless edge: distributed stochastic gradient descent over-the-air</a>, <i>IEEE Transactions on Signal Processing</i>, vol. 68, pp. 2155-2169, Apr. 2020. </li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://arxiv.org/pdf/1810.09992.pdf" target="_blank">Computation scheduling for distributed machine learning with straggling workers</a>, <i>IEEE Transactions on Signal Processing</i>, vol. 67, no. 24, pp. 6270-6284, Dec. 2019.</li>
             <li>Q. Yang, M. Mohammadi Amiri, and D. Gunduz, <a href="https://arxiv.org/pdf/1808.04835.pdf" target="_blank">Audience-retention-rate-aware caching and coded video delivery with asynchronous demands</a>, <i>IEEE Transactions on Communications</i>, vol. 67, no. 10, pp. 7088-7102, Oct. 2019.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/AG_JSAC_18.pdf" target="_blank">Caching and coded delivery over Gaussian broadcast channels for energy efficiency</a>, <i>IEEE Journal on Selected Areas in Communications</i>, vol. 36, no. 8, pp. 1706-1720, Aug. 2018.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/MAG_TC17.pdf" target="_blank">Cache-aided content delivery over erasure broadcast channels</a>, <i>IEEE Transactions on Communications</i>, vol. 66, no. 1, pp. 370-381, Jan. 2018.</li>
             <li>M. Mohammadi Amiri, Q. Yang, and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/AYG_TC16.pdf" target="_blank">Decentralized caching and coded delivery with distinct cache capacities</a>, <i>IEEE Transactions on Communications</i>, vol. 65, no. 11, pp. 4657-4669, Nov. 2017.</li>
             <li>M. Mohammadi Amiri and B. Maham, <a href="https://link.springer.com/article/10.1007/s11277-017-4443-5" target="_blank">Two novel adaptive transmission schemes in a decode-and-forward relaying network</a>, <i>Wireless Personal Communications</i>, vol. 96, no. 4, pp. 5705-5722, Oct. 2017.</li>
             <li>M. Mohammadi Amiri and D. Gunduz, <a href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/ipc-lab/AG_TC16.pdf" target="_blank">Fundamental limits of coded caching: Improved delivery rate-cache capacity trade-off</a>, <i>IEEE Transactions on Communications</i>, vol. 65, no. 2, pp. 806-815, Feb. 2017.</li>
             <li>M. Mohammadi Amiri, A. Olfat, and N. C. Beaulieu, <a href="https://ieeexplore.ieee.org/document/7084194" target="_blank">Novel beamforming scheme for multicasting in cooperative wireless networks with a multiple antenna relay</a>, <i>IEEE Transactions on Wireless Communications</i>, vol. 14, no. 8, pp. 4482-4493, Aug. 2015.</li>
          </ul> 
    
            
    
        </ul>   
    <!-- <script>// When the user clicks on div, open the popupfunction myFunction() {
      var popup = document.getElementById("myPopup");
      popup.classList.toggle("show");
    }</script>-->




    <!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Members %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% --> 
       
    <a name="members"></a></p><h2><a name="members"> Members</h2>

       <ul>
          <br>
          <li style="color:black;font-size:16px;"><b>Ph.D.</b></li>
          <br>
    
          <ul>
            <font color="black"> 
             <li><a href="https://sajadalipour7.github.io/" target="_blank">MohammadSajad Alipour</a> (Spring 2025)</li> 
             <li><a href="https://sadia-sigma-lab.github.io/" target="_blank">Sadia Asif</a> (Fall 2024)</li> 
             <li><a href="https://zzbright1998.github.io/" target="_blank">Yuxuan Zhu</a> (Fall 2023)</li>   
             <li><a href="https://yczzzzzz.github.io/" target="_blank">Yuchen Zhang</a> (Fall 2023)</li> 
             <li><a href="https://davidhy514.github.io/" target="_blank">David Hong Yang</a> (Fall 2023)</li> 
            </font>
            </ul>

          <br>
          <li style="color:black;font-size:16px;"><b>M.Sc.</b></li>
          <br>
    
          <ul>
            <font color="black">
             <li><a href="https://ryanjclin.github.io/" target="_blank">JuiChien Lin</a> (Fall 2023)</li> 
            </font>
            </ul>

          </ul>


       

    <!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Awards %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->  
       
    <a name="awards"><h2>Awards</h2>
    </a><ul>
    <!-- <li> Tenure track offer for W2 (associate) professorship at <a href="https://www.usnews.com/education/best-global-universities/saarland-university-504282">Saarland University</a>, Germany 2022 </li>-->
    <li><a href="https://www.comsoc.org/about/awards/paper-awards/ieee-communications-society-katherine-johnson-young-author-best-paper" target="_blank"> IEEE Communications Society Young Author Best Paper Award (2022)</a>, 
       paper &#34;Federated learning over wireless fading channels&#34;, IEEE Transactions on Wireless Communications, vol. 19, no. 5, pp. 3546-3557, May 2020.</li>
    <li> <b>Best PhD Thesis (2019)</b>, IEEE Information Theory Chapter of UK and Ireland.</li>
    <li> <b>Eryl Cadwallader Davies Prize - Outstanding PhD Thesis (2019)</b>, EEE Department, Imperial College London.</li>
    <li> <b>EEE Departmental Scholarship (2015 - 2019)</b>, Imperial College London.</li>
    <li> <b>Excellent Student (2014)</b>,  Ranked 1st among all M.Sc. students in ECE Department, University of Tehran. </li>
    <li> <b>Excellent Student (2011)</b>, Ranked 1st among all B.Sc. students in EE Department, Iran University of Science and Technology.</li>
    </ul>
    
    
    <!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Invited Talks %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% --> 
       
    <a name="talk"><h2>Invited Talks</h2></a>
    <ul> 
    <li><b>Collective intelligence</b>, Bell Labs, May 2023.</li>
    <li><b>Decentralized data valuation</b>, Decentralized Society + Web3 Research Panel, Media Lab Fall Meeting, Massachusetts Institute of Technology, Oct. 2022.</li>
    <li><b>Federated edge machine learning</b>, Keynote speaker at Futurewei University Days Workshop, Aug.  2021.</li>
    <li><b>Federated edge learning: advances and challenges</b>, Keynote speaker at IEEE International Conference on Communications, Networks and Satellite (COMNETSAT), Dec. 2020.</li>
    <li><b>Federated edge learning: advances and challenges</b>, King's College London, Nov.  2020.</li>
    <li><b>Federated edge learning: advances and challenges</b>, University of Maryland, Oct.  2020.</li>
    <li><b>Federated edge learning: advances and challenges</b>, University of Arizona, Oct.  2020.</li>
    <li><b>Federated learning: advances and challenges</b>, Virginia Polytechnic Institute and State University (Virginia Tech), Oct. 2020.</li>
    <li><b>Fundamental limits of coded caching</b>, Ohio State University, Nov.  2016.</li>
    <li><b>Fundamental limits of coded caching</b>, Stanford University, Nov.  2016.</li>
    </ul>


    <!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Services %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% --> 
       
    <a name="services"><h2>Academic Services</h2></a>
    
    <ul>
    <li style="color:black;font-size:16px;"><b>Program Chair </b></li>

       <ul>
       <li> <a href="https://sites.mit.edu/genaifordesign/">Generative AI for Design Workshop (DESAI)</a>, MIT, 2025. </li>
       </ul>  
       
    <li style="color:black;font-size:16px;"><b>Program Committee </b></li>
    
       <ul>
       <li> IEEE International Conference on Distributed Computing Systems, 2024. </li>
       <li> IEEE Global Communications Conference (Globecom), Wireless Communications for Distributed Intelligence (WCDI), 2023. </li>
       <li> IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), 2022.</li>
       <li> IEEE International Conference on Microwaves, Communications, Antennas Electronic Systems, 2021.</li>
       <li> IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), 2021.</li>
       <li> IEEE International Conference on Communications (ICC) Workshop - Edge Learning for 5G Mobile Networks and Beyond (EdgeLearn5G), 2021.</li>
       <li> IEEE International Conference on Communications (ICC): SAC Machine Learning for Communications Track, 2021.</li>
       <li> IEEE International Conference on Communications, Networks and Satellite (COMNETSAT), 2020.</li>
       <li> IEEE Global Communications Conference (Globecom), Cognitive Radio and AI-Enabled Networks (CRAEN), 2020.</li>
       <li> Conference on Information Sciences and Systems (CISS), 2020.</li>
       <li> IEEE International Conference on Communications (ICC) Workshop - Edge Machine Learning for 5G Mobile Networks and Beyond (EML5G), 2020.</li>
       </ul>  
    
    </ul>


    <!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Openings %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% --> 
       
    <a name="openings"><h2>Openings</h2></a>
    I am looking for motivated Ph.D. students with strong mathematical and analytical skills. Please send me your CV if you are interested in Machine Learning and comfortable with programming. 
    
    
    </td></tr></tbody></table></div>
    
    
    </body></html>
    
